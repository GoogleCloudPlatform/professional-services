jobs:
- stepId: 'SparkPi'
  sparkJob:
    args:
    - '1000'
    jarFileUris:
    - 'file:///usr/lib/spark/examples/jars/spark-examples.jar'
    mainClass: 'org.apache.spark.examples.SparkPi'
- stepId: 'MapReducePi'
  hadoopJob:
    args:
    - 'pi'
    - '16'
    - '1000'
    mainJarFileUri: 'file:///usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.9.2.jar'
  prerequisiteStepIds:
  - 'SparkPi'
placement:
  managedCluster:
    clusterName: 'ephemeral-cluster1'
    config:
      gceClusterConfig:
        internalIpOnly: true
        subnetworkUri: https://www.googleapis.com/compute/v1/projects/PROJECT/regions/us-central1/subnetworks/example-net-dataproc-central
        zoneUri: https://www.googleapis.com/compute/v1/projects/PROJECT/zones/us-central1-a
      masterConfig:
        diskConfig:
          bootDiskSizeGb: 500
          bootDiskType: pd-standard
        machineTypeUri: https://www.googleapis.com/compute/v1/projects/PROJECT/zones/us-central1-a/machineTypes/n1-standard-2
        numInstances: 1
      softwareConfig:
        imageVersion: preview
        properties:
          mapred:mapreduce.jobhistory.address: history-server-m:10020
          mapred:mapreduce.jobhistory.done-dir: gs://HISTORY_BUCKET/done-dir
          mapred:mapreduce.jobhistory.intermediate-done-dir: gs://HISTORY_BUCKET/intermediate-done-dir
          spark:spark.eventLog.dir: gs://HISTORY_BUCKET/spark-events/
          spark:spark.history.fs.logDirectory: gs://HISTORY_BUCKET/spark-events/
          spark:spark.yarn.historyServer.address: history-server-m:18080
      workerConfig:
        diskConfig:
          bootDiskSizeGb: 500
          bootDiskType: pd-standard
        machineTypeUri: https://www.googleapis.com/compute/v1/projects/PROJECT/zones/us-central1-a/machineTypes/n1-standard-2
        numInstances: 2
      initializationActions: 
      - executableFile: gs://HISTORY_BUCKET/init_actions/disable_history_servers.sh
