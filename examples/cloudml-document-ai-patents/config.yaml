# Copyright 2019 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# Config file for Document AI patents example training and prediction pipelines.

# The project the Document AI pipeline will be built and hosted in.
# TODO(michaelsherman): Make sure no line is past 80 characters (per bash style)
pipeline_project:
  project_id: # TODO(user): Set to your Project ID.
  region: 'us-central1' # Currently (Aug 2019) only "us-central1" supported.
  demo_sample_data: # TODO(user): GCS location of sample patents to process for demo
  demo_dataset_id: # TODO(user): BQ dataset to store information collected for demo

# Parameters for creation of a service account with get_service_acct.sh.
service_acct:
  creator_user_id: # TODO(user): Set to your GCP login email.
  acct_name: 'patent-service-acct'
  acct_description: 'Service-account-for-patent-demo'
  acct_display_name: 'Patent-Demo-Service-Account'
  key_path: '$HOME/keys/patent-demo-service-acct.json'

# TODO(michaelsherman): Each of these should just be a BQ proj.dataset.table, they should
#   be as independent as possible.
# TODO(michaelsherman): Fields should be specified for all models, like NER is.
pdp_project:
  project_id: 'bigquery-public-data' 
  dataset_id: 'labeled_patents' 
  bucket_name: 'gcs-public-data--labeled-patents'
  image_table_id: 'extracted_data' 
  objdetect_table_id: 'figures'
  text_table_id: 'invention_types'
  ner_table_id: 'extracted_data'
model_imgclassifier:
  model_id: # 'TODO(user): replace with model id when training is complete
  demo_table_id: 'document_classification'
model_objdetect:
  model_id: # 'TODO(user): replace with model id when training is complete
  demo_table_id: 'object_detection'
model_textclassifier:
  model_id: # 'TODO(user): replace with model id when training is complete
  demo_table_id: 'subject_classification'
model_ner:
  model_id: # 'TODO(user): replace with model id when training is complete
  demo_table_id: 'ner_results'
  fields_to_extract:
  - field_name: 'gcs_path'
  - field_name: 'publication_date'
  - field_name: 'class_international'
  - field_name: 'application_number'
  - field_name: 'filing_date'
  - field_name: 'applicant_line_1'
  - field_name: 'inventor_line_1'
  - field_name: 'title_line_1'
  - field_name: 'number'

